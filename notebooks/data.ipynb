{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "005e37ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import DataLoader, Dataset ,random_split\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06fad4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FishSegmentationDataset(Dataset):\n",
    "    def __init__(self, base_path, transform=None, mask_transform=None):\n",
    "        self.base_path = base_path\n",
    "        self.transform = transform\n",
    "        self.mask_transform = mask_transform\n",
    "        self.fish_categories = [d for d in os.listdir(base_path) \n",
    "                               if os.path.isdir(os.path.join(base_path, d))]\n",
    "        \n",
    "        \n",
    "        self.samples = []\n",
    "        \n",
    "        for category in self.fish_categories:\n",
    "            img_path = os.path.join(base_path, category, category)\n",
    "            mask_path = os.path.join(base_path, category, f\"{category} GT\")\n",
    "            \n",
    "            if not os.path.exists(img_path) or not os.path.exists(mask_path):\n",
    "                continue\n",
    "                \n",
    "            image_files = [f for f in os.listdir(img_path) if f.endswith('.png')]\n",
    "            image_files.sort(key=lambda x: int(x.split('.')[0]))\n",
    "            \n",
    "            for img_file in image_files:\n",
    "                img_full_path = os.path.join(img_path, img_file)\n",
    "                mask_full_path = os.path.join(mask_path, img_file)\n",
    "                \n",
    "                if os.path.exists(mask_full_path):\n",
    "                    self.samples.append({\n",
    "                        'image_path': img_full_path,\n",
    "                        'mask_path': mask_full_path\n",
    "                    })\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        \n",
    "        # Load image\n",
    "        image = Image.open(sample['image_path']).convert(\"L\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # Load mask\n",
    "        mask = Image.open(sample['mask_path']).convert(\"1\")\n",
    "        if self.mask_transform:\n",
    "            mask = self.mask_transform(mask)\n",
    "        \n",
    "        # Return only image and mask for segmentation\n",
    "        return image, mask\n",
    "\n",
    "class TestSegmentationDataset(Dataset):\n",
    "    def __init__(self, base_path, transform=None):\n",
    "        self.base_path = base_path\n",
    "        self.transform = transform\n",
    "        self.fish_categories = [d for d in os.listdir(base_path) \n",
    "                               if os.path.isdir(os.path.join(base_path, d))]\n",
    "        \n",
    "       \n",
    "        self.samples = []\n",
    "        \n",
    "        for category in self.fish_categories:\n",
    "            category_path = os.path.join(base_path, category)\n",
    "            \n",
    "            if not os.path.exists(category_path):\n",
    "                continue\n",
    "                \n",
    "            image_files = [f for f in os.listdir(category_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "            \n",
    "            for img_file in image_files:\n",
    "                img_full_path = os.path.join(category_path, img_file)\n",
    "                self.samples.append({\n",
    "                    'image_path': img_full_path\n",
    "                })\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        \n",
    "        # Load image\n",
    "        image = Image.open(sample['image_path']).convert(\"L\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image\n",
    "\n",
    "def TrainSegmentationDataloader(train_batch_size=64, val_batch_size=64, val_split=0.2):\n",
    "    base_path = \"../src/data/Fish_Dataset/A_Fish_Dataset\"\n",
    "    \n",
    "    # transforms\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    \n",
    "    mask_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Lambda(lambda x: (x > 0.5).float())\n",
    "    ])\n",
    "    \n",
    "    # full dataset\n",
    "    full_dataset = FishSegmentationDataset(base_path, transform, mask_transform)\n",
    "    \n",
    "    # Split dataset\n",
    "    total_size = len(full_dataset)\n",
    "    val_size = int(total_size * val_split)\n",
    "    train_size = total_size - val_size\n",
    "    \n",
    "    train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "    \n",
    "    # training dataloaders and validation dataloaders\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=val_batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "    \n",
    "    return train_dataloader, val_dataloader\n",
    "\n",
    "def TestSegmentationDataloader(batch_size=32):\n",
    "    test_base_path = \"../src/data/Fish_Dataset/NA_Fish_Dataset\"\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    \n",
    "    test_dataset = TestSegmentationDataset(test_base_path, transform)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "    \n",
    "    return test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c390bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batch: 2 items\n",
      "  Images: torch.Size([64, 1, 224, 224])\n",
      "  Masks: torch.Size([64, 1, 224, 224])\n",
      "Val batch: 2 items\n",
      "  Images: torch.Size([64, 1, 224, 224])\n",
      "  Masks: torch.Size([64, 1, 224, 224])\n",
      "Test batch: 32 items\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(test_batch, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(test_batch) == \u001b[32m1\u001b[39m:\n\u001b[32m     21\u001b[39m     test_images = test_batch[\u001b[32m0\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(test_batch, \u001b[43mtorch\u001b[49m.Tensor):\n\u001b[32m     23\u001b[39m     test_images = test_batch\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mNameError\u001b[39m: name 'torch' is not defined"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "train_dl, val_dl = TrainSegmentationDataloader()\n",
    "train_batch = next(iter(train_dl))\n",
    "print(f\"Train batch: {len(train_batch)} items\")\n",
    "if len(train_batch) == 2:\n",
    "    images, masks = train_batch\n",
    "    print(f\"  Images: {images.shape}\")\n",
    "    print(f\"  Masks: {masks.shape}\")\n",
    "\n",
    "val_batch = next(iter(val_dl))\n",
    "print(f\"Val batch: {len(val_batch)} items\")\n",
    "if len(val_batch) == 2:\n",
    "    val_images, val_masks = val_batch\n",
    "    print(f\"  Images: {val_images.shape}\")\n",
    "    print(f\"  Masks: {val_masks.shape}\")\n",
    "\n",
    "test_dl = TestSegmentationDataloader()\n",
    "test_batch = next(iter(test_dl))\n",
    "print(f\"Test batch: {len(test_batch)} items\")\n",
    "\n",
    "if isinstance(test_batch, tuple) and len(test_batch) == 1:\n",
    "    test_images = test_batch[0]\n",
    "elif isinstance(test_batch, torch.Tensor):\n",
    "    test_images = test_batch\n",
    "else:\n",
    "    test_images = test_batch  # fallback\n",
    "\n",
    "print(f\"  Test Images: {test_images.shape}\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "axes[0, 0].imshow(images[0].squeeze().numpy(), cmap='gray')\n",
    "axes[0, 0].set_title('Train Image')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "axes[0, 1].imshow(masks[0].squeeze().numpy(), cmap='gray')\n",
    "axes[0, 1].set_title('Train Mask')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "axes[0, 2].imshow(val_images[0].squeeze().numpy(), cmap='gray')\n",
    "axes[0, 2].set_title('Val Image')\n",
    "axes[0, 2].axis('off')\n",
    "\n",
    "axes[1, 0].imshow(val_masks[0].squeeze().numpy(), cmap='gray')\n",
    "axes[1, 0].set_title('Val Mask')\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "axes[1, 1].imshow(test_images[0].squeeze().numpy(), cmap='gray')\n",
    "axes[1, 1].set_title('Test Image')\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "axes[1, 2].axis('off')\n",
    "axes[1, 2].text(0.5, 0.5, 'No mask for\\ntest data', ha='center', va='center', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fishenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
